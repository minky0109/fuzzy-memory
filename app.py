import streamlit as st
import fitz  # PyMuPDF
import re
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸
st.set_page_config(page_title="ë¬¸í•­ ìœ ì‚¬ë„ ë¶„ì„ê¸°", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #FFF5F7; }
    h1, h2, h3 { color: #D63384; }
    div.stButton > button {
        width: 100%; background-color: #FFB6C1; color: white;
        border-radius: 12px; border: none; height: 3.5em; font-weight: bold; font-size: 1.1rem;
    }
    div.stButton > button:hover { background-color: #FF8DA1; color: white; transform: translateY(-2px); }
    .compare-box {
        border: 2px solid #FFB6C1; padding: 20px; border-radius: 15px;
        background-color: white; color: black; min-height: 200px; line-height: 1.7;
    }
    mark { background-color: #FFD1DC; color: black; font-weight: bold; border-radius: 3px; padding: 0 2px; }
    .streamlit-expanderHeader { border: 1px solid #FFB6C1 !important; border-radius: 10px !important; background-color: white !important; }
    </style>
    """, unsafe_allow_html=True)

# --- í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ë°€ í•„í„°ë§ í•¨ìˆ˜ ---
def extract_problems_with_pages(file):
    if file is None: return []
    
    # [ì¤‘ìš”] íŒŒì¼ ì½ê¸° ìœ„ì¹˜ ì´ˆê¸°í™” (í˜ì´ì§€ ëˆ„ë½ ë°©ì§€ í•µì‹¬)
    file.seek(0)
    
    doc = fitz.open(stream=file.read(), filetype="pdf")
    all_problems = []
    
    # [í•„í„°] ì ˆëŒ€ ë¬¸í•­ì´ ë  ìˆ˜ ì—†ëŠ” í‚¤ì›Œë“œ (ì—¬ê¸°ì— 'í™•ì¸ì‚¬í•­' ì¶”ê°€)
    exclude_keywords = [
        'ìˆ˜ëŠ¥íŠ¹ê°•', 'ë°œí–‰ì²˜', 'EBS', 'í˜ì´ì§€', 'ê³¼ëª©', 'í•™ë…„ë„', 
        'ëª¨ì˜í‰ê°€', 'ì‹œí—˜ì§€', 'êµì¬', 'íŒê¶Œ', 'í™•ì¸ì‚¬í•­', 'ìœ ì˜ì‚¬í•­', 
        'ì •ë‹µê³¼ í•´ì„¤', 'ìˆ˜í—˜ë²ˆí˜¸', 'ì„±ëª…'
    ]

    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        page_text = page.get_text()
        current_page_no = page_num + 1
        
        # 1. ë¬¸í•­ ë²ˆí˜¸(ìˆ«ì+ì , ìˆ«ì+ê´„í˜¸ ë“±) ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œê¸°
        split_text = re.split(r'\n(?=\d+[\.|\)])|(?<=\n)(?=\d+[\.|\)])|(?=\[\d+\])', page_text)
        
        for p in split_text:
            cleaned_p = p.strip()
            
            # [ì¡°ê±´ 1] ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ë¬´ì‹œ (45ì ë¯¸ë§Œ)
            if len(cleaned_p) < 45:
                continue
            
            # [ì¡°ê±´ 2] ì œì™¸ í‚¤ì›Œë“œ í•„í„°ë§ (íŠ¹íˆ 'í™•ì¸ì‚¬í•­' ì°¨ë‹¨)
            is_noise = False
            for key in exclude_keywords:
                if key in cleaned_p:
                    # í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ë°, ìˆ«ìë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ 100% ë…¸ì´ì¦ˆ(í—¤ë”/ê³µì§€)
                    if not re.match(r'^\d', cleaned_p):
                        is_noise = True
                        break
            
            if not is_noise:
                all_problems.append({
                    "text": cleaned_p, 
                    "page": current_page_no  # í˜„ì¬ ë¶„ì„ ì¤‘ì¸ ì‹¤ì œ í˜ì´ì§€ ë²ˆí˜¸ ê¸°ë¡
                })
                
    return all_problems

def highlight_common_words(text, reference_text):
    ref_words = set(re.findall(r'\b\w{2,}\b', reference_text))
    target_words = re.findall(r'\b\w{2,}\b', text)
    highlighted_text = text
    for word in sorted(list(set(target_words)), key=len, reverse=True):
        if word in ref_words:
            highlighted_text = re.sub(f'({re.escape(word)})', r'<mark>\1</mark>', highlighted_text)
    return highlighted_text

# --- UI ë ˆì´ì•„ì›ƒ ---
st.title("ğŸ” ë¬¸í•­ ìœ ì‚¬ë„ ì •ë°€ ë¶„ì„ê¸°")
st.write("PDFì˜ 'í™•ì¸ì‚¬í•­' ë“± ë¶ˆí•„ìš”í•œ ì •ë³´ëŠ” ì œì™¸í•˜ê³  ë¬¸í•­ë§Œ ì •ë°€í•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤.")

col1, col2 = st.columns(2)
with col1:
    st.markdown("#### ğŸ“˜ ê¸°ì¤€ PDF (ìˆ˜íŠ¹/í‰ê°€ì›)")
    file_origin = st.file_uploader("íŒŒì¼ ì„ íƒ", type="pdf", key="origin")
with col2:
    st.markdown("#### ğŸ“ ëŒ€ìƒ PDF (ì¶œì œ ë¬¸í•­)")
    file_new = st.file_uploader("íŒŒì¼ ì„ íƒ", type="pdf", key="new")

# ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
if file_origin and file_new:
    st.markdown("<br>", unsafe_allow_html=True)
    if st.button("âœ¨ ë¶„ì„ ì‹œì‘í•˜ê¸°"):
        with st.spinner('í˜ì´ì§€ë³„ ë¬¸í•­ì„ ì •ë°€í•˜ê²Œ ëŒ€ì¡°í•˜ëŠ” ì¤‘...'):
            list_origin = extract_problems_with_pages(file_origin)
            list_new = extract_problems_with_pages(file_new)
            
            if not list_origin or not list_new:
                st.error("íŒŒì¼ì—ì„œ ë¶„ì„ ê°€ëŠ¥í•œ ë¬¸í•­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                results = []
                vectorizer = TfidfVectorizer()
                
                for i, new_item in enumerate(list_new):
                    new_p = new_item['text']
                    best_score, best_match, found_page = 0, "ë§¤ì¹­ í•­ëª© ì—†ìŒ", 0
                    
                    for origin_item in list_origin:
                        origin_p = origin_item['text']
                        try:
                            tfidf = vectorizer.fit_transform([new_p, origin_p])
                            score = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]
                            if score > best_score:
                                best_score, best_match, found_page = score, origin_p, origin_item['page']
                        except: continue
                    
                    results.append({
                        "id": i + 1, "score": round(best_score * 100, 1),
                        "origin": best_match, "new": new_p, "page": found_page
                    })
                st.session_state.results = results

# ê²°ê³¼ ì„¹ì…˜
if 'results' in st.session_state:
    st.markdown("---")
    st.subheader("ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸")
    
    for res in st.session_state.results:
        status = "âœ…"
        page_display = f"{res['page']}p" if res['page'] > 0 else "ì •ë³´ì—†ìŒ"
        page_tag = ""
        
        if res['score'] > 40:
            status = "ğŸš¨ ìœ„í—˜" if res['score'] > 70 else "âš ï¸ ì£¼ì˜"
            page_tag = f" [ì›ë³¸ {page_display}]"
        
        label = f"{status} | {res['id']}ë²ˆ ë¬¸í•­ (ìœ ì‚¬ë„ {res['score']}%){page_tag}"
        
        with st.expander(label):
            h_new = highlight_common_words(res['new'], res['origin'])
            h_origin = highlight_common_words(res['origin'], res['new'])
            
            c1, c2 = st.columns(2)
            with c1:
                st.markdown(f"<div class='compare-box'><b>[ì¶œì œ ë¬¸í•­]</b><hr>{h_new}</div>", unsafe_allow_html=True)
            with c2:
                st.markdown(f"<div class='compare-box'><b>[ê¸°ì¤€ ë¬¸í•­ - {page_display}]</b><hr>{h_origin}</div>", unsafe_allow_html=True)
