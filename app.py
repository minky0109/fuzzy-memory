import streamlit as st
import fitz  # PyMuPDF
import re
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸
st.set_page_config(page_title="ë¬¸í•­ ìœ ì‚¬ë„ ë¶„ì„ê¸°", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #FFF5F7; }
    h1, h2, h3 { color: #D63384; }
    div.stButton > button {
        width: 100%; background-color: #FFB6C1; color: white;
        border-radius: 12px; border: none; height: 3.5em; font-weight: bold;
    }
    .compare-box {
        border: 2px solid #FFB6C1; padding: 20px; border-radius: 15px;
        background-color: white; color: black; min-height: 150px; line-height: 1.6;
    }
    mark { background-color: #FFD1DC; color: black; font-weight: bold; border-radius: 3px; }
    </style>
    """, unsafe_allow_html=True)

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ---
def extract_problems_with_pages(file):
    if file is None: return []
    doc = fitz.open(stream=file.read(), filetype="pdf")
    all_problems = []
    for page_num, page in enumerate(doc):
        page_text = page.get_text()
        split_text = re.split(r'\n(?=\d+[\.|\)])|(?<=\n)(?=\d+[\.|\)])|(?=\[\d+\])', page_text)
        for p in split_text:
            cleaned_p = p.strip()
            if len(cleaned_p) > 15:
                all_problems.append({"text": cleaned_p, "page": page_num + 1})
    return all_problems

def highlight_common_words(text, reference_text):
    ref_words = set(re.findall(r'\b\w{2,}\b', reference_text))
    target_words = re.findall(r'\b\w{2,}\b', text)
    highlighted_text = text
    for word in sorted(list(set(target_words)), key=len, reverse=True):
        if word in ref_words:
            # íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬ë¥¼ ìœ„í•´ re.escape ì‚¬ìš©
            highlighted_text = re.sub(f'({re.escape(word)})', r'<mark>\1</mark>', highlighted_text)
    return highlighted_text

# --- UI ì„¹ì…˜ ---
st.title("ğŸ” ë¬¸í•­ ìœ ì‚¬ë„ ì •ë°€ ë¶„ì„ê¸°")

# ë³€ìˆ˜ ì´ˆê¸°í™” (NameError ë°©ì§€)
file_origin = None
file_new = None

col1, col2 = st.columns(2)
with col1:
    st.markdown("#### ğŸ“˜ ê¸°ì¤€ PDF (ìˆ˜íŠ¹/í‰ê°€ì›)")
    file_origin = st.file_uploader("íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type="pdf", key="origin_upload")
with col2:
    st.markdown("#### ğŸ“ ëŒ€ìƒ PDF (ì¶œì œì)")
    file_new = st.file_uploader("íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type="pdf", key="new_upload")

# 2. ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
if file_origin is not None and file_new is not None:
    st.markdown("<br>", unsafe_allow_html=True)
    if st.button("âœ¨ ë¶„ì„ ì‹œì‘í•˜ê¸°"):
        with st.spinner('í˜ì´ì§€ë³„ ë°ì´í„°ë¥¼ ì •ë°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
            list_origin = extract_problems_with_pages(file_origin)
            list_new = extract_problems_with_pages(file_new)
            
            results = []
            if list_origin and list_new:
                vectorizer = TfidfVectorizer()
                for i, new_item in enumerate(list_new):
                    new_p = new_item['text']
                    best_score, best_match, found_page = 0, "ë§¤ì¹­ í•­ëª© ì—†ìŒ", 0
                    
                    for origin_item in list_origin:
                        origin_p = origin_item['text']
                        try:
                            tfidf = vectorizer.fit_transform([new_p, origin_p])
                            score = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]
                            if score > best_score:
                                best_score, best_match, found_page = score, origin_p, origin_item['page']
                        except: continue
                    
                    results.append({
                        "id": i + 1, "score": round(best_score * 100, 1),
                        "origin": best_match, "new": new_p, "page": found_page
                    })
                st.session_state.results = results
            else:
                st.error("íŒŒì¼ì—ì„œ ë¬¸í•­ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. PDF í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# 3. ê²°ê³¼ í‘œì‹œ
if 'results' in st.session_state:
    st.markdown("---")
    st.subheader("ğŸ“‹ ë¶„ì„ ê²°ê³¼")
    for res in st.session_state.results:
        status = "âœ…"
        page_info = ""
        if res['score'] > 40:
            status = "ğŸš¨ ìœ„í—˜" if res['score'] > 70 else "âš ï¸ ì£¼ì˜"
            page_info = f" [ì›ë³¸ {res['page']}í˜ì´ì§€]"
        
        label = f"{status} | {res['id']}ë²ˆ ë¬¸í•­ (ìœ ì‚¬ë„: {res['score']}%){page_info}"
        with st.expander(label):
            h_new = highlight_common_words(res['new'], res['origin'])
            h_origin = highlight_common_words(res['origin'], res['new'])
            c1, c2 = st.columns(2)
            with c1: st.markdown(f"<div class='compare-box'><b>[ì¶œì œ ë¬¸í•­]</b><hr>{h_new}</div>", unsafe_allow_html=True)
            with c2: st.markdown(f"<div class='compare-box'><b>[ê¸°ì¤€ ë¬¸í•­ - {res['page']}p]</b><hr>{h_origin}</div>", unsafe_allow_html=True)
