import streamlit as st
import fitz  # PyMuPDF
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸
st.set_page_config(page_title="ë¬¸í•­ ìœ ì‚¬ë„ ë¶„ì„ê¸°", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #FFF5F7; }
    h1, h2, h3 { color: #D63384; }
    div.stButton > button {
        width: 100%; background-color: #FFB6C1; color: white;
        border-radius: 12px; border: none; height: 3.5em; font-weight: bold;
    }
    .compare-box {
        border: 2px solid #FFB6C1; padding: 20px; border-radius: 15px;
        background-color: white; color: black; min-height: 250px; line-height: 1.8;
    }
    mark { background-color: #FFC0CB; color: black; font-weight: bold; border-radius: 3px; padding: 0 2px; }
    </style>
    """, unsafe_allow_html=True)

# --- [í•µì‹¬ ìˆ˜ì •] ë¬¸í•­ê³¼ ì„ ì§€ë¥¼ í•˜ë‚˜ë¡œ ë¬¶ëŠ” ì¶”ì¶œ í•¨ìˆ˜ ---
def extract_problems_with_pages(file):
    if file is None: return []
    file.seek(0)
    doc = fitz.open(stream=file.read(), filetype="pdf")
    all_problems = []
    
    noise_keywords = ['í•™ë…„ë„', 'ì˜ì—­', 'í™•ì¸ì‚¬í•­', 'ìœ ì˜ì‚¬í•­', 'ì„±ëª…', 'ìˆ˜í—˜ë²ˆí˜¸', 'ìƒí™œê³¼ ìœ¤ë¦¬']

    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        page_text = page.get_text("text")
        
        # ì¤„ë°”ê¿ˆ ë‹¨ìœ„ë¡œ ë¨¼ì € ìª¼ê°¬
        lines = page_text.split('\n')
        
        current_prob = ""
        for line in lines:
            cleaned_line = line.strip()
            if not cleaned_line: continue
            
            # ìƒˆ ë¬¸í•­ì˜ ì‹œì‘ íŒ¨í„´ (ìˆ«ì. ë˜ëŠ” [ìˆ«ì] ë˜ëŠ” ìˆ«ì))
            is_new_start = bool(re.match(r'^(\d+[\.|\)]|\[\d+\])', cleaned_line))
            
            # ë§Œì•½ ìƒˆ ë²ˆí˜¸ë¡œ ì‹œì‘í•˜ê³ , ê¸°ì¡´ì— ìŒ“ì¸ ë¬¸ì¥ì´ ìˆë‹¤ë©´ ì €ì¥
            if is_new_start and current_prob:
                # ë…¸ì´ì¦ˆ í•„í„°ë§ í›„ ì €ì¥
                if len(current_prob) >= 45 and not any(nk in current_prob[:30] for nk in noise_keywords):
                    all_problems.append({"text": current_prob, "page": page_num + 1})
                current_prob = cleaned_line # ìƒˆ ë¬¸í•­ ì‹œì‘
            else:
                # ë²ˆí˜¸ë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ì„ ì§€ë‚˜ ë³¸ë¬¸ ë‚´ìš©ì€ ì´ì „ ë‚´ìš©ì— í•©ì¹¨
                if current_prob:
                    current_prob += " " + cleaned_line
                else:
                    # ë¬¸ì„œ ë§¨ ì²˜ìŒ ì‹œì‘ ì²˜ë¦¬
                    current_prob = cleaned_line

        # ë§ˆì§€ë§‰ ë¬¸í•­ ì²˜ë¦¬
        if current_prob and len(current_prob) >= 45:
            all_problems.append({"text": current_prob, "page": page_num + 1})
                
    return all_problems

# --- [ë³€ë³„ë ¥ í•˜ì´ë¼ì´íŠ¸] 6ê¸€ì ì´ìƒ ì¼ì¹˜ ì‹œ ---
def highlight_selective(target, reference):
    ref_stripped = re.sub(r'\s+', '', reference)
    min_match_len = 6 
    
    to_highlight = []
    for i in range(len(target) - min_match_len + 1):
        chunk = target[i:i+min_match_len]
        if len(chunk.strip()) < min_match_len: continue
        
        chunk_stripped = re.sub(r'\s+', '', chunk)
        if chunk_stripped in ref_stripped:
            to_highlight.append(chunk)

    sorted_chunks = sorted(list(set(to_highlight)), key=len, reverse=True)
    result = target
    for chunk in sorted_chunks:
        if chunk in result:
            result = result.replace(chunk, f"[[M_S]]{chunk}[[M_E]]")
    
    result = result.replace("[[M_S]]", "<mark>").replace("[[M_E]]", "</mark>")
    return re.sub(r'</mark><mark>', '', result)

# --- UI ë ˆì´ì•„ì›ƒ ---
st.title("ğŸ” ë¬¸í•­ ìœ ì‚¬ë„ ì •ë°€ ë¶„ì„ê¸°")

col1, col2 = st.columns(2)
with col1:
    file_origin = st.file_uploader("ğŸ“˜ ê¸°ì¤€ PDF (ìˆ˜íŠ¹/í‰ê°€ì›)", type="pdf", key="origin")
with col2:
    file_new = st.file_uploader("ğŸ“ ëŒ€ìƒ PDF (ì¶œì œ ë¬¸í•­)", type="pdf", key="new")

if file_origin and file_new:
    st.markdown("<br>", unsafe_allow_html=True)
    if st.button("âœ¨ ë¶„ì„ ì‹œì‘í•˜ê¸°"):
        with st.spinner('ë¬¸í•­ê³¼ ì„ ì§€ë¥¼ í†µí•©í•˜ì—¬ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
            list_origin = extract_problems_with_pages(file_origin)
            list_new = extract_problems_with_pages(file_new)
            
            if list_origin and list_new:
                results = []
                vectorizer = TfidfVectorizer(ngram_range=(1, 2))
                
                for i, new_item in enumerate(list_new):
                    new_p = new_item['text']
                    best_score, best_match, found_page = 0, "", 0
                    
                    for origin_item in list_origin:
                        origin_p = origin_item['text']
                        try:
                            tfidf = vectorizer.fit_transform([new_p, origin_p])
                            score = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]
                            if score > best_score:
                                best_score, best_match, found_page = score, origin_p, origin_item['page']
                        except: continue
                    
                    results.append({
                        "id": i + 1, "score": round(best_score * 100, 1),
                        "origin": best_match, "new": new_p, "page": found_page
                    })
                st.session_state.results = results

if 'results' in st.session_state:
    st.markdown("---")
    for res in st.session_state.results:
        status = "âœ…"
        if res['score'] > 65: status = "ğŸš¨ ìœ„í—˜"
        elif res['score'] > 35: status = "âš ï¸ ì£¼ì˜"
        
        label = f"{status} | {res['id']}ë²ˆ ë¬¸í•­ (ìœ ì‚¬ë„ {res['score']}%)[ì›ë³¸ {res['page']}p]"
        with st.expander(label):
            h_new = highlight_selective(res['new'], res['origin'])
            h_origin = highlight_selective(res['origin'], res['new'])
            
            c1, c2 = st.columns(2)
            with c1: st.markdown(f"<div class='compare-box'><b>[ì¶œì œ ë¬¸í•­]</b><hr>{h_new}</div>", unsafe_allow_html=True)
            with c2: st.markdown(f"<div class='compare-box'><b>[ê¸°ì¤€ ë¬¸í•­ - {res['page']}p]</b><hr>{h_origin}</div>", unsafe_allow_html=True)
